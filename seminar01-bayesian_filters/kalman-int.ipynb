{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зачем нужны фильтры и почему Байесовы\n",
    "## Начнем с фильтров, что они делают?\n",
    "Чаще всего под фильтром понимают сущность, которая умеет пропускать \"хороший\" вход и выкидывать \"плохой\".\n",
    "\n",
    "![](img/not-a-filter.png)\n",
    "\n",
    "Сегодня речь пойдет о вероятностных фильтрах. Задача таких фильтров - выделять полезный сигнал из шумного входа.\n",
    "\n",
    "![](img/noisy_measurements.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хорошо, что такое \"шумный вход\"\n",
    "\n",
    "Типичный пример шумного входа в контексте фильтра Калмана - GPS сигнал. На качество сигнала GPS оказывает влияние множество факторов. Даже в поле показания GPS будут отличаться от измерения к измерению.\n",
    "\n",
    "![](img/gnss_error_sources.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кейс посложнее: мы не всегда можем измерять то, что хотим знать\n",
    "\n",
    "Как узнать, едет ли вражеская машина?\n",
    "![](img/latent_velocity.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## С чем нам приходится работать\n",
    "\n",
    "* Мы не уверены в измерениях, но можем говорить о вероятности ошибки измерения ($z$)\n",
    "* Мы не измеряем интересные вещи напрямую, т.е. работаем с латентными переменными ($x$)\n",
    "\n",
    "$P(x \\vert z) = \\frac{P(z \\vert x) P(x)}{P(z)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Про фильтр Калмана"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Фи́льтр Ка́лмана — эффективный рекурсивный фильтр, оценивающий вектор состояния динамической системы, используя ряд неполных и зашумленных измерений. Назван в честь Рудольфа Калмана.\n",
    "\n",
    "[Википедия](https://ru.wikipedia.org/wiki/Фильтр_Калмана)\n",
    "\n",
    "## Какой еще системы?\n",
    "\n",
    "В первую очередь мы ожидаем, что нам известны законы (хорошо когда *линейные*), по которым развивается эта система. Текущие характеристики системы формируют вектор состояния, а величины, влияющие на систему, формируют вектор управления.\n",
    "\n",
    "![](img/dynamic.png)\n",
    "Например, в задаче оценки положения автомобиля вектором состояния в момент времени $k$ может являться положение автомобиля $x_{k}$, а вектором управления - ее скорость $v_{k}$. Зная эти характеристики можно построить предсказание состояния в момент времени $k+1$: \n",
    "$$x_{k+1} = x_{k} + \\Delta t \\cdot v_k$$, \n",
    "где $\\Delta t$ - разница времени между отсчетами.\n",
    "\n",
    "\n",
    "\n",
    "## А что значит рекурсивный фильтр?\n",
    "\n",
    "![](img/recursive.png)\n",
    "\n",
    "Пусть мы знаем $x_{k-1}$ - оценку латентных переменных на момент времени $k-1$ \n",
    "\n",
    "1) Мы пронаблюдали  $z_{k-1}$\n",
    "\n",
    "2) Используем эту оценку для уточнения $x_{k-1}$\n",
    "\n",
    "3) Зная динамику системы, предсказываем $x_k$, ждем нового измерения $z_k$, идем в первый пункт, рекурсия\n",
    "\n",
    "\n",
    "В примере с машиной мы могли бы измерять ее позицию используя GPS, тогда разумно в качестве $x_k$ взять что-то средние между предсказанием $x_{k-1} + \\Delta t \\cdot v_{k-1}$ и измерением $z_k$.\n",
    "\n",
    "В этом и есть суть фильтра Калмана. Математика, лежащая в его основе, объясняет, почему усреднение предсказания и наблюдения работает, а также подбирает степень, с которой надо верить каждому из слагаемых при усреднении.\n",
    "\n",
    "\n",
    "## Почему фильтра Калмана назван в определении эффективным?\n",
    "\n",
    "При некоторых допущениях он дает оптимальную оценку вектора состояния.\n",
    "\n",
    "В качестве бонуса фильтр достаточно легко считается: все что нам потребуется - обращать матрицы небольшой размерности.\n",
    "\n",
    "А теперь немного простой математики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейный фильтр Калмана\n",
    "\n",
    "См. детали [тут](http://www.probabilistic-robotics.org/)\n",
    "\n",
    "### Состояние и управление\n",
    "\n",
    "$x_k$ - вектор состояния системы в момент времени $k$, считаем, что $x_k \\sim N(\\mu_k, \\Sigma_k)$\n",
    "\n",
    "$u_{k}$ - вектор управления системы в момент времени $k$. Вектор управления не является случайной величиной, эти значения нам известны на каждом шаге.\n",
    "\n",
    "Зная динамику системы, мы можем записать выражение для предсказания $\\hat{x}_{k+1}$ состояния системы в момент времени $k+1$:\n",
    "\n",
    "$$\\hat{x}_{k+1} = A_{k+1} \\cdot x_k + B_{k+1} \\cdot u_{k+1} + \\epsilon_{k+1}$$\n",
    ", где $A_{k+1}$, $B_{k+1}$ - известные матрицы, задающие динамику системы, $\\epsilon_{k+1} \\sim N(0, R_{k+1})$ - случайный шум (например, моторы робота не в точности выполняют команды или вектор управления измеряется не точно).\n",
    "\n",
    "Обратите внимание, что $\\hat{x}_{k+1}$ - это именно предсказание состояния на основе динамики, а не само состояние $x_{k+1}$, которое будет получено далее с учетом измерения системы.\n",
    "\n",
    "В том, что динамика системы линейна и состоит линейность фильтра.\n",
    "\n",
    "Последнее выражение можно эквивалентно переписать в вероятностном виде:\n",
    "$$p(x_{k+1} \\vert u_{k+1} x_{k}) \\sim N(A_{k+1} \\cdot x_k + B_{k+1} \\cdot u_{k+1}, R_{k+1})$$\n",
    "Это априорное распределение на состояние в момент времени $k+1$.\n",
    "\n",
    "### Измерение\n",
    "Считаем, что измерение линейно зависит от состояния, но подвержено влиянию некоторого шума $\\delta_k \\sim N(0, Q_k)$\n",
    "$$z_k = C_k x_k + \\delta_k$$ \n",
    "То же самое в вероятностном виде:\n",
    "$$p(z_k \\vert x_k) \\sim N(C_k x_k, Q_k)$$\n",
    "\n",
    "### Предсказание\n",
    "Используя формулу полной вероятности можно записать\n",
    "\n",
    "$$p(x_{k} \\vert u_{k}) = \\int p(x_{k} \\vert u_{k} x_{k-1}) p(x_{k-1}) d x_{k-1}$$\n",
    "\n",
    "Произведение двух нормальных распределений $N(A_{k} \\cdot x_{k-1} + B_{k} \\cdot u_{k}, R_{k})$ и $N(\\mu_{k-1}, \\Sigma_{k-1})$ проинтегрированное по $x_{k-1}$ - нормальное распределение \n",
    "\n",
    "$$p(x_k \\vert u_k) \\sim N(B_k u_k + A_k \\mu_{k-1}, A_k \\Sigma_{k-1} A_k^T + R_k) = N(\\hat{\\mu_k}, \\hat{\\Sigma_k})$$\n",
    "\n",
    "Тут некотрая математика, но интуитивно ясно: мы ожидаем увидеть робота там, куда он поехал (мат ожидание распределения), при этом мы не знали, где он был в начале (первый член дисперсии), и не знаем, насколько точно он нас слушается (второй член дисперсии).\n",
    "\n",
    "### Учет измерения\n",
    "Пришло время написать финальное выражение для состояния системы в момент $k$. Используя формулу Байеса можем записать\n",
    "$$p(x_k \\vert z_k u_k) \\sim  p(z_k \\vert x_k u_k) p(x_k \\vert u_k)$$\n",
    "\n",
    "\n",
    "Опять имеем произведение двух нормальных распределений $N(C_k x_k, Q_k) N(\\hat{\\mu_k}, \\hat{\\Sigma_k})$. Чему оно эквивалентно? \n",
    "\n",
    "Верно, нормальному распределению (в этот раз с [выводом](kalman-update-derivation.ipynb)),\n",
    "\n",
    "$K_k = \\hat{\\Sigma_k} C_k^T (C_k \\hat{\\Sigma_k} C_k^T + Q_k)^-$\n",
    "\n",
    "$\\mu_k = \\hat{\\mu_k} +K_k (z_k - C_k \\hat{\\mu_k})$\n",
    "\n",
    "$\\Sigma_k = (I - K_k C_k) \\hat{\\Sigma_k}$\n",
    "\n",
    "Такое $K_k$ является оптимальным, если искать $\\mu_k$ в виде линейной комбинации измерения и предсказания и пытаться минимизировать сумму квадратов отклонений $x_k$ от $\\mu_k$ ([подробности](kalman-update-derivation.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь все вместе\n",
    "\n",
    "### Имеем\n",
    "\n",
    "$x_{k-1}$ вектор состояния системы, случайная величина $x_{k-1} \\sim N(\\mu_{k-1}, \\Sigma_{k-1})$\n",
    "\n",
    "В момент времени $k$ поступает измерение $z_k$ и управление $u_k$\n",
    "\n",
    "Динамика системы и модель измерения считаются линейными:\n",
    "\n",
    "$$x_{k} = A_k x_{k-1} + B_k u_k + \\epsilon_k$$\n",
    "\n",
    "$$z_{k} = C_k x_k + \\delta_k$$\n",
    "\n",
    "Шумы $\\epsilon_k$ и $\\delta_k$ являются случайными и распределены по нормальному закону\n",
    "\n",
    "$$\\epsilon_k \\sim N(0, R_k)$$\n",
    "\n",
    "$$\\delta_k \\sim N(0, Q_k)$$\n",
    "\n",
    "#### 1) Предсказание \n",
    "\n",
    "$$\\hat{\\mu_k} = B_k u_k + A_k \\mu_{k-1}$$\n",
    "\n",
    "$$\\hat{\\Sigma_k} = A_k \\Sigma_{k-1} A_k^T + R_k$$\n",
    "\n",
    "#### 2) Обновление\n",
    "\n",
    "$$K_k = \\hat{\\Sigma_k} C_k^T (C_k \\hat{\\Sigma_k} C_k^T + Q_k)^-$$\n",
    "\n",
    "$$\\mu_k = \\hat{\\mu_k} +K_k (z_k - C_k \\hat{\\mu_k})$$\n",
    "\n",
    "$$\\Sigma_k = (I - K_k C_k) \\hat{\\Sigma_k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robot import robot\n",
    "from measurer import global_measurer\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from IPython import display\n",
    "import time\n",
    "from matplotlib.lines import Line2D\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kalman(object):\n",
    "    \"\"\"\n",
    "    Simple kalman filter\n",
    "    We use robot position as it's state and (noisy) observation of robot velocity as a control\n",
    "    We assume that we can measure position directly, but with some noise\n",
    "    \"\"\"\n",
    "    def __init__(self, measure_noise=1, control_noise=(0.1, 0.1)):\n",
    "        # TODO: we don't know where robot is, how to say it using\n",
    "        #       its position mu and sigma?\n",
    "        self.position_mu = None\n",
    "        self.position_sigma = None\n",
    "        \n",
    "        self.last_measure_time = 0\n",
    "        \n",
    "        self.measure_noise = measure_noise\n",
    "        self.control_noise = control_noise\n",
    "        \n",
    "    def _A(self, t):\n",
    "        # TODO state transition matrix\n",
    "        #      our state is position, what is $x_{t+1}$ given $x_t$\n",
    "        #      without control?\n",
    "        pass\n",
    "    \n",
    "    def _B(self, t):\n",
    "        dt = (t - self.last_measure_time)\n",
    "        # TODO control transition matrix\n",
    "        #      how control (velocity) $u$ affects our state if applied during time $dt$\n",
    "        pass\n",
    "    \n",
    "    def _R(self, t):\n",
    "        R = np.eye(2)\n",
    "        \n",
    "        # TODO\n",
    "        # what is state transition noise, given that all uncertainty we have is\n",
    "        # going from velocity measurement\n",
    "        \n",
    "        return R\n",
    "    \n",
    "    def _C(self, t):\n",
    "        # TODO\n",
    "        # what is our measurement (2x2) matrix (hint: we measure position directly)\n",
    "        return None\n",
    "    \n",
    "    def _Q(self, t):\n",
    "        # TODO what is uncertainty of our measurement\n",
    "        return None\n",
    "        \n",
    "    def predict(self, robot_velocity, t):\n",
    "        # TODO: implement, robot_velocity is a control vector here\n",
    "        predicted_mu = None\n",
    "        predicted_sigma = None\n",
    "        \n",
    "        self.position_mu = predicted_mu\n",
    "        self.position_sigma = predicted_sigma\n",
    "    \n",
    "    def update(self, position, t):\n",
    "        #TODO implement, position is a measurement here\n",
    "        # prior to update we have called predict, thus we have predictions in state varaibles\n",
    "        K_t = None\n",
    "        \n",
    "        self.position_mu = None\n",
    "        self.position_sigma = None\n",
    "        self.last_measure_time = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_position(position, covariance, color='black', ax=None):\n",
    "    \"\"\"\n",
    "    Confidence ellipse of 3 sigma\n",
    "    \"\"\"\n",
    "    lambda_, v = np.linalg.eig(covariance)\n",
    "    lambda_ = np.sqrt(lambda_)\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.subplot(111, aspect='equal')\n",
    "\n",
    "    ell = Ellipse(xy=(position),\n",
    "                  width=lambda_[0]*2, height=lambda_[1]*2,\n",
    "                  angle=np.rad2deg(np.arccos(v[0, 0])))\n",
    "    \n",
    "    ell.set_facecolor('none')\n",
    "    ell.set_edgecolor(color)\n",
    "    ax.add_artist(ell)\n",
    "    \n",
    "    ax.set_xlim(-7, 7)\n",
    "    ax.set_ylim(-7, 7)\n",
    "    \n",
    "    \n",
    "    ax.scatter(position[0], position[1], c=color)\n",
    "    return axaposterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = robot.Robot(pos=np.array((-7, 0)), vel=np.array((0.5, 0.1)), odometer_noise_x=0.5, odometer_noise_y=0.1)\n",
    "m = global_measurer.GlobalMeasurer(noise=0.3)\n",
    "k = Kalman(control_noise=(0.5, 0.1), measure_noise=0.3)\n",
    "\n",
    "dt = 0.5\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = plt.subplot(111, aspect='equal')\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color='red', lw=4),\n",
    "                Line2D([0], [0], color='blue', lw=4),\n",
    "                Line2D([0], [0], color='black', lw=4),\n",
    "                Line2D([0], [0], color='green', lw=4)]\n",
    "\n",
    "\n",
    "real_track = []\n",
    "measured_track = []\n",
    "kalman_track = []\n",
    "\n",
    "# TODO\n",
    "# Use kalman in a loop: \n",
    "# 1) use prior state to get prediction\n",
    "# 2) get a measurement \n",
    "# 3) update kalman state\n",
    "\n",
    "for i in range(40):\n",
    "    ax.clear()\n",
    "    \n",
    "    ax.legend(custom_lines, ['Kalman', 'Prediction', 'Measurement', 'Real position'])\n",
    "    \n",
    "    # TODO make kalman prediction and draw it, using 'blue' color\n",
    "\n",
    "    pos = m.measure(r)\n",
    "    draw_position(pos, np.eye(2) * k.measure_noise**2, ax=ax)\n",
    "    \n",
    "    #TODO get kalman update and draw it with 'red'\n",
    "    \n",
    "    ax.scatter(r.state_[0], r.state_[1], marker='x', color='green')\n",
    "    \n",
    "    real_track.append((r.state_[0], r.state_[1]))\n",
    "    measured_track.append(pos)\n",
    "    kalman_track.append(k.position_mu)\n",
    "\n",
    "    t += dt\n",
    "    r.move(dt)\n",
    "        \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    time.sleep(1.0)\n",
    "\n",
    "display.clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_track = np.array(measured_track)\n",
    "real_track = np.array(real_track)\n",
    "kalman_track = np.array(kalman_track)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(111, aspect='equal')\n",
    "plt.plot(measured_track[:, 0], measured_track[:, 1], '.:', c=\"black\", label='Measurement')\n",
    "plt.plot(kalman_track[:, 0], kalman_track[:, 1], 'r.:', label=\"Kalman\")\n",
    "plt.plot(real_track[:, 0], real_track[:, 1], 'gx', label=\"Real position\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
