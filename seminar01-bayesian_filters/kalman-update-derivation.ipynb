{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О том, как выводить Калмана\n",
    "\n",
    "Имеем произведение двух экспонент, показатели просуммируем и назовем $J_k$\n",
    "\n",
    "$p(x_k \\vert z_k u_k) = \\eta \\exp \\left( J_k \\right)$\n",
    "\n",
    "$J_k = \\frac{1}{2} (z_k - C_k x_k)^T Q_k^-(z_k - C_k x_k) + \\frac{1}{2} (x_k - \\hat{\\mu_k})^T \\hat{\\Sigma_k}^-(x_k - \\hat{\\mu_k})$\n",
    "\n",
    "Понятно, что это квадратичная форма по $x_k$\n",
    "\n",
    "Минимум у нее - в среднем, а дисперсия равна второй производной\n",
    "\n",
    "$\\frac{\\partial J_k}{\\partial x_k} = -C_k^T Q_k^- (z_k - C_k x_k) + \\hat{\\Sigma_k}^-(x_k - \\hat{\\mu_k})$\n",
    "\n",
    "$\\frac{\\partial^2 J_k}{\\partial^2 x_k} = C_k^T Q_k^- C_k + \\hat{\\Sigma_k}^-$\n",
    "\n",
    "С дисперсией ($\\Sigma_k$) разобрались $\\Sigma_k = (C_k^T Q_k^- C_k + \\hat{\\Sigma_k}^-)^-$\n",
    "\n",
    "Среднее (назовем его $\\mu_k$) дается нулем производной\n",
    "\n",
    "$\\hat{\\Sigma_k}^-(\\mu_k - \\hat{\\mu_k}) = C_k^T Q_k^- (z_k - C_k \\mu_k)$\n",
    "\n",
    "$C_k^T Q_k^- (z_k - C_k \\mu_k) = C_k^T Q_k^- (z_k - C_k \\mu_k + C_k \\hat{\\mu_k} - C_k \\hat {\\mu_k}) = C_k^T Q_k^- (z_k - C_k \\hat{\\mu_k}) - C_k^T Q_k^-C_k(\\mu_k - \\hat {\\mu_k})$\n",
    "\n",
    "Подставим обратно и перенесем второе слагаемое налево\n",
    "\n",
    "$(C_k^T Q_k^-C_k + \\hat{\\Sigma_k}^-)(\\mu_k - \\hat{\\mu_k}) = C_k^T Q_k^- (z_k - C_k \\hat{\\mu_k})$\n",
    "\n",
    "$\\Sigma_k^- (\\mu_k - \\hat{\\mu_k}) = C_k^T Q_k^- (z_k - C_k \\hat{\\mu_k})$\n",
    "\n",
    "$\\mu_k = \\Sigma_k C_k^T Q_k^- (z_k - C_k \\hat{\\mu_k}) + \\hat{\\mu_k}$\n",
    "\n",
    "Назовем $K_k = \\Sigma_k C_k^T Q_k^-$\n",
    "\n",
    "$\\mu_k = \\hat{\\mu_k} + K_k (z_k - C_k \\hat{\\mu_k})$\n",
    "\n",
    "\n",
    "Последнее выражение завершает вывод формул.\n",
    "Полученные формулы для $\\Sigma_k$, $\\mu_k$, $K_k$ можно эквивалентно переписать в следующем виде:\n",
    "\n",
    "$K_k = \\hat{\\Sigma_k} C_k^T (C_k \\hat{\\Sigma_k} C_k^T + Q_k)^-$\n",
    "\n",
    "$\\mu_k = \\hat{\\mu_k} +K_k (z_k - C_k \\hat{\\mu^k})$\n",
    "\n",
    "$\\Sigma_k = (I - K_k C_k) \\hat{\\Sigma_k}$\n",
    "\n",
    "Такая форма удобнее с точки зрения времени вычисления, т.к. тут обращается матрица размерности наблюдений, что зачастую меньше размерности состояния."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Об оптимальных свойствах Калмана\n",
    "\n",
    "Пусть до получения измерения мы оценили вектор состояния как $x_{k \\vert k-1} \\sim N(\\hat{\\mu_k}, \\hat{\\Sigma_k})$\n",
    "\n",
    "$x_k \\sim N(\\mu_k, \\Sigma_k)$ и положим, что $\\mu_k = \\hat{\\mu_k} + K_k(z_k - C_k \\hat{\\mu_k})$ - это соответствует нашей интуиции о том, что состояние должно быть где-то между измерением и предсказанием.\n",
    "\n",
    "Будем искать такой $K_k$, чтобы минимизировать дисперсию  $x_k$, что эквивалентно минимизации следа матрицы $\\Sigma_k$\n",
    "\n",
    "$\\Sigma_k = cov(x_k - \\mu_k) = cov(x_k - \\hat{\\mu_k} - K_k(z_k - C_k \\hat{\\mu_k}))$\n",
    "\n",
    "$= cov(x_k - \\hat{\\mu_k} - K_k z_k + K_k C_k \\hat{\\mu_k})$\n",
    "\n",
    "$= cov(x_k - \\hat{\\mu_k} - K_k C_k x_k - K_k \\delta_k + K_k C_k \\hat{\\mu_k})$\n",
    "\n",
    "Шум измерения не зависит от $x_k$ и обладает ковариацией $Q_k$\n",
    "\n",
    "$= cov(x_k - \\hat{\\mu_k} - K_k C_k x_k + K_k C_k \\hat{\\mu_k}) + K_k Q_k K_k^T$\n",
    "\n",
    "$= cov((x_k - \\hat{\\mu_k}) (I - K_k C_k)) + K_k Q_k K_k^T$\n",
    "\n",
    "$= (I - K_k C_k) \\hat{\\Sigma_k} (I - K_k C_k)^T + K_k Q_k K_k^T$\n",
    "\n",
    "$= \\hat{\\Sigma_k} - K_k C_k \\hat{\\Sigma_k} - \\hat{\\Sigma_k} C_k^T K_k^T + K_k (Q_k + C_k \\hat{\\Sigma_k} C_k^T) K_k^T$\n",
    "\n",
    "$S_k = (Q_k + C_k \\hat{\\Sigma_k} C_k^T)$ - ковариационная матрица шума измерения\n",
    "\n",
    "$= \\hat{\\Sigma_k} - K_k C_k \\hat{\\Sigma_k} - \\hat{\\Sigma_k} C_k^T K_k^T + K_k S_k K_k^T$\n",
    "\n",
    "$= \\hat{\\Sigma_k} + (K_k - \\hat{\\Sigma_k} C_k^T S_k^-) S_k (K_k - \\hat{\\Sigma_k} C_k^T S_k^-)^T - \\hat{\\Sigma_k} C_k^T S_k^- C_k \\hat{\\Sigma_k}$ (тут существенно используется то, что раз $S_k$ ковариационная матрица, то $S_k = S_k^T$)\n",
    "\n",
    "$= \\left[ \\hat{\\Sigma_k} - \\hat{\\Sigma_k} C_k^T S_k^- C_k \\hat{\\Sigma_k} \\right] + \\left[ (K_k - \\hat{\\Sigma_k} C_k^T S_k^-) S_k (K_k - \\hat{\\Sigma_k} C_k^T S_k^-)^T \\right]$\n",
    "\n",
    "Мы хотим минимизировать след этой матрицы по $K_k$, при этом только второе слагаемое зависит от $K_k$. Кроме того, видно, что это слагаемое является некоторой матрицей ковариации, а значит его след в лучшем случае может быть равен нулю, т.е. оптимальное $K_k$ - то, которое обнуляет это слагаемое:\n",
    "\n",
    "$K_k = \\hat{\\Sigma_k} C_k^T S_k^- = \\hat{\\Sigma_k} C_k^T (C_k \\hat{\\Sigma_k} C_k^T + Q_k)^-$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
